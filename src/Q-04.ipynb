{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sattwik-sahu/dse316-hw01/blob/main/src/Q-04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GB7a16CkJN9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import SVHN\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxS2qBR5iWEy",
        "outputId": "c1cad7e7-bc3b-429e-fac7-1403f75a450a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to /home/moonlab/dl_assign/data/train_32x32.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 182040794/182040794 [00:04<00:00, 39414514.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "Training LeNet-5 on SVHN dataset\n",
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 2.2512270519306568\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 2, Loss: 2.214317493563656\n",
            "Accuracy of the network on the test images: 20 %\n",
            "Epoch 3, Loss: 2.103314858336636\n",
            "Accuracy of the network on the test images: 32 %\n",
            "Epoch 4, Loss: 1.7040621198420962\n",
            "Accuracy of the network on the test images: 52 %\n",
            "Epoch 5, Loss: 1.2015032200834117\n",
            "Accuracy of the network on the test images: 69 %\n",
            "Epoch 6, Loss: 0.8919994810262621\n",
            "Accuracy of the network on the test images: 76 %\n",
            "Epoch 7, Loss: 0.7257499212000568\n",
            "Accuracy of the network on the test images: 79 %\n",
            "Epoch 8, Loss: 0.6308288539080641\n",
            "Accuracy of the network on the test images: 80 %\n",
            "Epoch 9, Loss: 0.5648655469761145\n",
            "Accuracy of the network on the test images: 81 %\n",
            "Epoch 10, Loss: 0.517629336061436\n",
            "Accuracy of the network on the test images: 82 %\n",
            "Finished Training and Evaluating the model\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Transformation for LeNet-5\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4377, 0.4438, 0.4728], std=[0.1980, 0.2010, 0.1970])\n",
        "])\n",
        "\n",
        "\n",
        "# Adjusted LeNet-5 for SVHN\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)  # Adjusted for 3-channel input\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*6*6, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.tanh(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*6*6)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load the SVHN dataset\n",
        "#Change the root path\n",
        "train_dataset = datasets.SVHN(root='/home/moonlab/dl_assign/data', split='train', download=True, transform=transform)\n",
        "#create subset\n",
        "subset_indices = np.random.choice(len(train_dataset), len(train_dataset) // 4, replace=False)\n",
        "dataset_subset = torch.utils.data.Subset(train_dataset, subset_indices)\n",
        "# Split the dataset\n",
        "train_size = int(0.8 * len(dataset_subset))\n",
        "test_size = len(dataset_subset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset_subset, [train_size, test_size])\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "# Training and evaluation\n",
        "def train_and_evaluate(model, train_loader, test_loader):\n",
        "    print('Training and Evaluating the model')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
        "\n",
        "\n",
        "#Saving the model\n",
        "# def save_model(model, model_name):\n",
        "#     print(f'Saving the model {model_name}')\n",
        "#     torch.save(model.state_dict(), f'./SavedModels/{model_name}.pt')\n",
        "\n",
        "\n",
        "def choose_model():\n",
        "    print('------------------------------------------')\n",
        "    print('Training LeNet-5 on SVHN dataset')\n",
        "    model = LeNet5().to(device)\n",
        "    train_and_evaluate(model, train_loader, test_loader)\n",
        "    # save_model(model, 'lenet_svhn')\n",
        "    print('Finished Training and Evaluating the model')\n",
        "    print('------------------------------------------')\n",
        "\n",
        "choose_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL3dyrlljS7c",
        "outputId": "edb4ee9d-8ede-4d4d-c97a-86cc6814e25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /home/moonlab/dl_assign/data/train_32x32.mat\n",
            "-------------------------------------\n",
            "Training and evaluating alexnet\n",
            "Loading alexnet\n",
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 3.4699016783435273\n",
            "Accuracy of the network on the test images: 18 %\n",
            "Epoch 2, Loss: 2.2387172717714936\n",
            "Accuracy of the network on the test images: 18 %\n",
            "Epoch 3, Loss: 2.238653300630994\n",
            "Accuracy of the network on the test images: 18 %\n",
            "Epoch 4, Loss: 2.2367682321623423\n",
            "Accuracy of the network on the test images: 18 %\n",
            "Epoch 5, Loss: 2.237156054859078\n",
            "Accuracy of the network on the test images: 18 %\n"
          ]
        }
      ],
      "source": [
        "#Transformation for Alexnet, VGG16 and Resnet\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "# Load the SVHN dataset\n",
        "#Change the root path\n",
        "full_dataset = SVHN(root='/home/moonlab/dl_assign/data', split='train', transform=transform, download=True)\n",
        "subset_indices = np.random.choice(len(full_dataset), len(full_dataset) // 4, replace=False)\n",
        "dataset_subset = Subset(full_dataset, subset_indices)\n",
        "# Split the dataset\n",
        "train_size = int(0.8 * len(dataset_subset))\n",
        "test_size = len(dataset_subset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset_subset, [train_size, test_size])\n",
        "#data loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "# Get the modified model\n",
        "def get_modified_model(model_name):\n",
        "    print(f\"Loading {model_name}\")\n",
        "    if model_name == 'alexnet':\n",
        "        model = models.alexnet(pretrained=True)\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(pretrained=True)\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
        "    elif model_name in ['resnet18', 'resnet50', 'resnet101']:\n",
        "        model = getattr(models, model_name)(pretrained=True)\n",
        "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model name\")\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Training and evaluation\n",
        "def train_and_evaluate(model, train_loader, test_loader):\n",
        "    print('Training and Evaluating the model')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
        "\n",
        "#Saving the model\n",
        "# def save_model(model, model_name):\n",
        "#     print(f'Saving the model {model_name}')\n",
        "#     torch.save(model.state_dict(), f'./SavedModels/{model_name}.pt')\n",
        "\n",
        "\n",
        "def choose_model():\n",
        "    model_names = ['alexnet', 'vgg16', 'resnet18', 'resnet50', 'resnet101']\n",
        "    for model_name in model_names:\n",
        "        print('-------------------------------------')\n",
        "        print(f\"Training and evaluating {model_name}\")\n",
        "        model = get_modified_model(model_name)\n",
        "        train_and_evaluate(model, train_loader, test_loader)\n",
        "        # save_model(model, model_name)\n",
        "        print('Finished Training and Evaluating the model')\n",
        "        print('-------------------------------------')\n",
        "\n",
        "choose_model()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzAIYE9dFbBEhzaqG9/1qS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}